2007 Database Cracking

2009 Reconstruction(Sideway Cracking)

2010 Merge cracking(Self-selecting, self-tuning, incrementally optimized indexes)

2011 Merging what's Cracked, Cracking What's Merged: Adaptive Indexing in Main-memory Column-Stores

2012 随机Cracking

2013 Uncracked Pieces

2014 Fast scan, not poor sort(Predicate Crack-in-tow)
2014 Partition的分析

2015 Radix Partition

2015 Database Cracking的评估与分析

2018 Adaptive Adaptive Indexing

2018 Cracking kernal分析

2019 Progressive Indexes


# Database Cracking
Database Cracking

数据库索引提供了**非歧视**的导航结构来定位数组，维护成本由数据库更新期间承担。索引维护是查询的副产品而不是更新的副产品。

连续的物理重组 作为 查询的一部分。按照用户的查询请求（谓词）自动组织数据。

第一次在属性A上范围查询时，复制A称为A的cracker column，记作A<sub>ack</sub>。A<sub>ack</sub>会根据查询持续进行重组。

随着查询越来越多，cracker colunmn被持续的划分成越来越多的片，需要一种方式进行快速定位片，所以给cracker column引入了一个cracker索引(AVL树)。AVL树上的每个节点的值 左包含还是右包含 需要额外信息。

学习单个查询，可以加速将来请求相似的多个查询。

与排序和构建索引的比较。如果事先知道查询要查什么属性，并且有足够的时间来排序（构建索引），那么直接排序（构建索引）当然是更好的选择。

Cracking适用于以下环境：
+ 不知道对数据的哪些部分感兴趣，属性和范围都是
+ 更新后没有足够的时间维护物理顺序
另外Cracking允许为每个属性维护独立的物理顺序(我觉得类似于允许范围查询的二级索引)。并且与排序或构建索引相比，这是一个轻量级操作。

具体的算法就是两个，Crack-in-two，把一段一分为二， Crack-in-three，把一段一分为三。注意的是，分段的时候不会把支点放到正确的位置上，而是在AVL上标注出属于左子树还是右子树。这里的Crack-in-two也被称为branching Crack-in-two，是因为这种比较方式会带来大量的分支指令的预测错误，影响性能。

Database Cracking中提到的一些未来研究方向：并发；超出内存；何时Crack；先验的Crack

# Reconstruction(Sidewag Cracking)
列存储中元组以来tid进行重构。
部分横向cracking，以自组织的方式最小化元组的构建代价。



# Self-selecting, self-tuning, incrementally optimized indexes
最早提出Adaptive Merging的论文。

索引太少需要大量的扫描；索引太多又增加了更新成本。还有不可预测的查询——这是索引建立的问题。解决这个问题又两种方法：
+ 更快的扫描
+ 根据工作负载调整索引。当前索引选择工具依赖于监视请求和执行计划，有时候创建或移除表上或者仕途上的索引。这样的工具三个缺点：1.在监视和创建之间的间隔可能已经超出了特定请求模式的持续时间，导致这个工具没有提供任何帮助。 2.就算不是上面的情况，间隔时间还是无法提供帮助。 3.最后传统索引会平等对待所有行，即使有些访问很多有些不访问。

Database Cracking的缺点：
1. 就是不对预设最小Partition(4MB)进一步cracking，也需要很多步才能到达最终表示。
2. 把初始数据表示转化为优化的有序的索引依赖于查询模式，也就是引入的边界值和支点值的顺序。
3. 如果crack留下来一个未排序的最小分区（如4MB），那么查询效率将永远无法达到传统索引的效率。
4. Database Cracking更适合内存数据库，不适合块访问存储。
   
之前的方法研究都集中于自动的决定要那个索引要创建，合并或删除。索引的调整与创建的代价都算到了工作负载中。一旦作出决定就会影响这个属性的所有范围。 
Database Cracking 永不查询的范围永远不会分区或者优化，与传统索引相比，这是自适应索引的优势；另一方面，从原始列到完全排序的索引列，每个数据都会移动多次。

本文的想法是，原来的Database Cracking是基于分区基于快排的，适合内存数据库，这里为适用于块访问的提出了基于合并的算法，是在分区B树的基础上做的。

下面看如何实现的：

![索引创建.png](https://upload-images.jianshu.io/upload_images/11576561-57e50e8f6eb5d4bc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

+ 初始索引的创建：这个在Database Cracking中就是把原始列复制(然后进行一次Crack)，在这里是把数据先分成等大的块，然后对每个块进行快排。如上图，图中同一颜色表示同一范围，最终得到的是范围重叠的，内部有序的多个partition。分成多少块取决于输入大小和内存分配。
+ 第二次查询时，现在已经有了适当的索引，尽管还没有完全优化合并到同一个分区中。这时，一个查询需要在每个分区中找到所需的record，通常是在一个B树内从低到高的扫描。扫描可以同时扫描多个分区，把多个有序流合并为一个，然后把这些records写到一个partition，并返回结果。
![查询.png](https://upload-images.jianshu.io/upload_images/11576561-24f2de8b4675c1c7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
+ Partition的合并：多个Partition可以合并成一个Partition，这里可以定义最小fan-in。
+ 后续的查询：首先分析本查询和之前的查询是否有重叠的范围，重叠部分去已排序合并的Partition查找，未重叠部分去初始Partitions中查找。未重叠部分合并成一个Partition后与前面重叠部分合并。——这种Partition与Partition之间的合并是很简单的，因为范围是不重叠的。
+ 每个key range的合并次数等于外部合并排序的合并深度。W是初始Partition数，fan-in为F，那么合并次数也就是log<sub>F</sub>(W) 次.

事实上，每个record的合并次数是与Database Cracking的主要区别。对于1GB的数据，Database Cracking的最小Partition为4MB(小于4MB不再进行分区)，那么每个record需要移动log<sub>2</sub>(1GB/4MB) = 8次，而对于adaptive merging来说，如果把1GB数据分为16MB大小，合并fan-in设为64，那么合并的次数是log<sub>64</sub>(1GB/16MB) = 1，也就是说每个record只需要移动一次就可以到它的最终位置。

**总结：** Adaptive Merging和Database Cracking一个是归并排序，一个是快速排序，但是更深层的原因在于合并可以多路合并，但是Cracking只提供了Cracking-in-two和Cracking-in-three。但是Adaptive Merging的一个主要问题在于初期较大的构建成本，它需要对每个块进行排序。

# Merging What’s Cracked, Cracking What’s Merged: Adaptive Indexing in Main-Memory Column-Stores

自适应索引技术的成本与收益的比较点：初始化成本，查询的开销和索引收敛到针对特定工作负载完全优化的速度。

这里提出了Database Cracking+Adaptive Merging的混合技术，旨在较低的初始成本和较快的收敛速度。两种技术是互补的，Cracking初始成本低，Merging的收敛速度快。设计了一系列的混合算法。
![2020-11-02 15-38-19屏幕截图.png](https://upload-images.jianshu.io/upload_images/11576561-7322c3368f1e4fc7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里尤其关注第一个查询产生的初始化成本，因为它代表着最坏情况下的自适应索引的成本和开销——只查询这么一次以后都不再查询的代价。
![2020-11-02 15-52-12屏幕截图.png](https://upload-images.jianshu.io/upload_images/11576561-013a333e707b4879.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

实现上：
+ First Query把所有元组都分配给所有未排序的初始分区（与Adaptive Merging的区别就是不排序），每个分区都能放入内存（甚至Cache）
+ 后续的查询，元组从初始分区移动到最终分区，并更新内容表和自适应索引(反映哪个key range被移动到了最终分区来让后来的查询直到哪部分去最终分区中查找哪部分去初始分区中查找)
+ 一旦所有的数据从初始分区P消耗掉，p就释放掉

每个初始分区都用一个表来追踪它包含的key range。一个主表也就是自适应索引本身，会追踪初始分区和最终分区的内容。当初始分区的一个key range中的元组移动到最终分区后 两部分都需要更新(追踪)。所用的数据结构和物理组织都是横向Cracking的。

本文主要继承了Adaptive Merging的思路，将自适应索引分为两部分，一部分是初始分区，代表着First Query的成本，也就是自适应索引的创建成本，以第一次查询的响应时间表示；另一部分是最终分区的处理，这决定了后续查询的成本和收敛到最优索引的速度。而对这两部分进行处理都有三种方式排序、Crack和Radix。

![混搭风.png](https://upload-images.jianshu.io/upload_images/11576561-0a8821c95332eddc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里给出了九种方法，但是考虑到给初始分区排序的初期成本非常高，所以不考虑HS*的方案。

![HCC和HRR的介绍.png](https://upload-images.jianshu.io/upload_images/11576561-d0fb62fca67212c1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

如上图：
HCC(Crack Crack)流程如下：首次查询，先把所有数据都分配给初始分区们，然后每个初始分区进行Crack，把满足查询要求的数据移入到最终分区中（注意：这里并没有像Adaptive merging一样把来自所有初始分区中满足查询的数据进行排序，也就是说最终分区中的数据也是无序的。）；后续查询，对于前面没有查询过的数据部分像前面一样，在初始分区Crack，把满足要求的数据新建一个最终分区，对于之前已经查询过的数据部分 是已经在最终分区中了，在这里对最终分区进行Crack。图4.

HRR(Radix Radix)流程：首次查询，把所有数据分配给所有初始分区们，然后在每个分区内进行基数划分，之后进行查询Crack，满足要求（进行基数分区后）放入最终分区；后续查询，没有查询过的部分如前，查询过的部分继续往下进行基数分区。

此外还有HCR和HRC，和上面的过程也是类似的。

![实验结果.png](https://upload-images.jianshu.io/upload_images/11576561-fcebfbab47e19ef3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

实验结果显示HCS也就是先crack初始分区，排序最终分区的方法，初始成本只是扫描的两倍左右，但收敛速度极快。

**本文中提出了一些影响性能的因素，包含：选择度，数据偏斜，更新，并发查询和基于磁盘的处理**

# Stochastic Database Cracking: Towards Robust Adaptive Indexing in Main-memory Column-Stores
前面的自适应索引方法并不稳定，很大程度上取决于查询工作负载。这种脆弱性主要是因为它把前面的查询当做金科玉律，盲目的重组前面查询范围内的数据，即使这样的操作非常昂贵且后续收益很少。

